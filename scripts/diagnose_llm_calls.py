"""
è¯Šæ–­è„šæœ¬ï¼šæ£€æµ‹ CrewAI ä½¿ç”¨çš„ LLM è°ƒç”¨æ–¹å¼
ç”¨äºå¸®åŠ©æ­£ç¡® patch LLM ç›‘æ§
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
ROOT_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT_DIR))

print("=" * 80)
print("CrewAI LLM è°ƒç”¨è¯Šæ–­")
print("=" * 80)

# 1. æ£€æŸ¥ LiteLLM
print("\n1. Check LiteLLM...")
try:
    import litellm
    version = getattr(litellm, '__version__', 'unknown')
    print(f"[OK] LiteLLM installed: {version}")
    
    # åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ–¹æ³•
    methods = [m for m in dir(litellm) if not m.startswith('_') and callable(getattr(litellm, m))]
    llm_methods = [m for m in methods if 'complet' in m.lower() or 'chat' in m.lower()]
    
    print(f"\n   å¯ç”¨çš„ LLM è°ƒç”¨æ–¹æ³•:")
    for method in llm_methods:
        print(f"   - {method}")
    
except ImportError as e:
    print(f"âŒ LiteLLM æœªå®‰è£…: {e}")

# 2. æ£€æŸ¥ CrewAI
print("\n2. æ£€æŸ¥ CrewAI...")
try:
    import crewai
    version = getattr(crewai, '__version__', 'unknown')
    print(f"âœ… CrewAI å·²å®‰è£…: {version}")
    
    from crewai import Agent, Task, Crew
    
    # æ£€æŸ¥ Agent çš„æ–¹æ³•
    print(f"\n   Agent æ–¹æ³•:")
    agent_methods = [m for m in dir(Agent) if not m.startswith('_') and 'task' in m.lower()]
    for method in agent_methods:
        print(f"   - {method}")
    
    # æ£€æŸ¥ Task çš„æ–¹æ³•
    print(f"\n   Task æ–¹æ³•:")
    task_methods = [m for m in dir(Task) if not m.startswith('_') and 'execut' in m.lower()]
    for method in task_methods:
        print(f"   - {method}")
    
except ImportError as e:
    print(f"âŒ CrewAI æœªå®‰è£…: {e}")

# 3. å°è¯•åˆ›å»ºæµ‹è¯• Agent å¹¶æŸ¥çœ‹å…¶ LLM é…ç½®
print("\n3. æ£€æŸ¥ Agent çš„ LLM é…ç½®...")
try:
    from crewai import Agent
    from dotenv import load_dotenv
    
    load_dotenv(ROOT_DIR / ".env")
    
    test_agent = Agent(
        role="Test Agent",
        goal="Test",
        backstory="Test",
        verbose=False
    )
    
    # æ£€æŸ¥ agent çš„ LLM ç›¸å…³å±æ€§
    llm_attrs = [attr for attr in dir(test_agent) if 'llm' in attr.lower()]
    print(f"\n   Agent çš„ LLM ç›¸å…³å±æ€§:")
    for attr in llm_attrs:
        if not attr.startswith('_'):
            try:
                value = getattr(test_agent, attr)
                print(f"   - {attr}: {type(value).__name__}")
            except:
                print(f"   - {attr}: (æ— æ³•è®¿é—®)")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ client æˆ–å…¶ä»–è°ƒç”¨æ–¹å¼
    if hasattr(test_agent, 'llm'):
        print(f"\n   Agent.llm ç±»å‹: {type(test_agent.llm)}")
        print(f"   Agent.llm æ¨¡å—: {type(test_agent.llm).__module__}")
        
        # æ£€æŸ¥ llm å¯¹è±¡çš„æ–¹æ³•
        if hasattr(test_agent.llm, '__dict__'):
            print(f"\n   Agent.llm çš„å±æ€§:")
            for key, value in test_agent.llm.__dict__.items():
                if not key.startswith('_'):
                    print(f"   - {key}: {type(value).__name__}")
    
except Exception as e:
    print(f"âŒ æ— æ³•åˆ›å»ºæµ‹è¯• Agent: {e}")
    import traceback
    traceback.print_exc()

# 4. æ£€æŸ¥å®é™…çš„è°ƒç”¨æ ˆ
print("\n4. å°è¯• Patch å¹¶æµ‹è¯•...")
try:
    import litellm
    
    # è®°å½•è°ƒç”¨
    call_count = [0]  # ä½¿ç”¨åˆ—è¡¨ä»¥ä¾¿åœ¨é—­åŒ…ä¸­ä¿®æ”¹
    
    original_completion = litellm.completion
    
    def test_patch(*args, **kwargs):
        call_count[0] += 1
        model = kwargs.get('model', 'unknown')
        print(f"   âœ… æ•è·åˆ°è°ƒç”¨ #{call_count[0]}: model={model}")
        print(f"      Args: {[type(a).__name__ for a in args]}")
        print(f"      Kwargs keys: {list(kwargs.keys())}")
        return original_completion(*args, **kwargs)
    
    litellm.completion = test_patch
    
    print("\n   å·² patch litellm.completionï¼Œå°è¯•è°ƒç”¨...")
    
    # æ¨¡æ‹Ÿä¸€ä¸ªç®€å•è°ƒç”¨
    try:
        from crewai import Agent
        from dotenv import load_dotenv
        import os
        
        load_dotenv(ROOT_DIR / ".env")
        
        # ç¡®ä¿æœ‰ç¯å¢ƒå˜é‡
        if not os.getenv('OPENAI_API_KEY'):
            print("   âš ï¸  æœªè®¾ç½® OPENAI_API_KEYï¼Œè·³è¿‡æµ‹è¯•è°ƒç”¨")
        else:
            test_agent = Agent(
                role="Test",
                goal="Say hello",
                backstory="Test agent",
                verbose=True
            )
            
            # æ³¨æ„ï¼šè¿™é‡Œä¸å®é™…æ‰§è¡Œ taskï¼Œåªæ˜¯æ£€æŸ¥ patch æ˜¯å¦å·¥ä½œ
            print(f"   Agent åˆ›å»ºæˆåŠŸï¼Œpatch æµ‹è¯•å®Œæˆ")
            print(f"   æ•è·åˆ°çš„è°ƒç”¨æ¬¡æ•°: {call_count[0]}")
    
    except Exception as e:
        print(f"   âš ï¸  æµ‹è¯•è°ƒç”¨å¤±è´¥: {e}")
    
    # æ¢å¤åŸå§‹å‡½æ•°
    litellm.completion = original_completion
    
except Exception as e:
    print(f"âŒ Patch æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 80)
print("è¯Šæ–­å®Œæˆ")
print("=" * 80)

print("\nğŸ“ å»ºè®®:")
print("1. å¦‚æœçœ‹åˆ° 'litellm.completion' è¢«è°ƒç”¨ï¼Œè¯´æ˜ patch ä½ç½®æ­£ç¡®")
print("2. å¦‚æœæœªæ•è·åˆ°è°ƒç”¨ï¼Œå¯èƒ½ CrewAI ä½¿ç”¨äº†å…¶ä»–æ–¹å¼ï¼ˆå¦‚ç›´æ¥è°ƒç”¨ OpenAI APIï¼‰")
print("3. æŸ¥çœ‹ä¸Šé¢çš„ Agent.llm ä¿¡æ¯ï¼Œäº†è§£å®é™…ä½¿ç”¨çš„ LLM å®¢æˆ·ç«¯ç±»å‹")
print("4. å¯èƒ½éœ€è¦ patch æ›´åº•å±‚çš„ API (å¦‚ openai.ChatCompletion.create)")
