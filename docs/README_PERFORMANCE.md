# ğŸš€ MAG ç³»ç»Ÿæ€§èƒ½ç›‘æ§å¿«é€ŸæŒ‡å—

## å¿«é€Ÿå¼€å§‹

### 1ï¸âƒ£ è¿è¡Œç³»ç»Ÿï¼ˆè‡ªåŠ¨å¯ç”¨ç›‘æ§ï¼‰

```bash
cd d:\AAAresearch\agent\crewai\mag-system
python -m src.main
```

è¿è¡Œæ—¶ä½ ä¼šçœ‹åˆ°å®æ—¶çš„æ€§èƒ½ç›‘æ§è¾“å‡ºï¼š

```
ğŸ“Š æ€§èƒ½ç›‘æ§å·²å¯åŠ¨ - Session ID: 20260206_143025
============================================================
å¼€å§‹ Patch CrewAI ä»¥æ·»åŠ æ€§èƒ½ç›‘æ§...
============================================================
âœ… å·²æˆåŠŸ patch LiteLLM completion å‡½æ•°è¿›è¡Œæ€§èƒ½ç›‘æ§
âœ… å·²æˆåŠŸ patch Agent.execute_task æ–¹æ³•è¿›è¡Œæ€§èƒ½ç›‘æ§
âœ… å·²æˆåŠŸ patch Task.execute æ–¹æ³•è¿›è¡Œæ€§èƒ½ç›‘æ§
============================================================
âœ… CrewAI æ€§èƒ½ç›‘æ§ Patch å®Œæˆ
============================================================

â±ï¸  LLM è°ƒç”¨å¼€å§‹ - Model: deepseek-chat | Prompt tokens (ä¼°ç®—): ~245
ğŸ¤– LLM è°ƒç”¨ [deepseek-chat]: 12.45s | Tokens: 1234 | Context: agent=architect
ğŸ”§ Tool è°ƒç”¨ [ReadFileTool]: 0.023s | Agent: architect
...
```

### 2ï¸âƒ£ æŸ¥çœ‹æ€§èƒ½æŠ¥å‘Š

è¿è¡Œå®Œæˆåï¼Œè‡ªåŠ¨ç”Ÿæˆä¸¤ä¸ªæŠ¥å‘Šæ–‡ä»¶ï¼š

```
storage/performance_logs/
â”œâ”€â”€ performance_report_20260206_143025.json    # è¯¦ç»†æ•°æ®ï¼ˆJSONï¼‰
â””â”€â”€ performance_summary_20260206_143025.txt    # å¯è¯»æ‘˜è¦ï¼ˆæ–‡æœ¬ï¼‰
```

**ç›´æ¥æ‰“å¼€æ–‡æœ¬æ‘˜è¦æŸ¥çœ‹ï¼š**

```bash
notepad storage\performance_logs\performance_summary_20260206_143025.txt
```

ä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„åˆ†æï¼š

```
================================================================================
æ€§èƒ½åˆ†ææŠ¥å‘Š - Session: 20260206_143025
================================================================================

ğŸ“Š æ€»æ‰§è¡Œæ—¶é—´: 245.67ç§’ (4.09åˆ†é’Ÿ)

================================================================================
ğŸ¤– LLM API è°ƒç”¨ç»Ÿè®¡
================================================================================
  è°ƒç”¨æ¬¡æ•°: 15
  æ€»è€—æ—¶: 180.23ç§’
  å¹³å‡è€—æ—¶: 12.02ç§’/æ¬¡
  å æ€»æ—¶é—´æ¯”ä¾‹: 73.4%  ğŸ‘ˆ ä¸»è¦ç“¶é¢ˆï¼

================================================================================
ğŸ“ˆ æ—¶é—´åˆ†å¸ƒ
================================================================================
  LLM API è°ƒç”¨: 73.4% (180.23ç§’)   ğŸ‘ˆ å¤§éƒ¨åˆ†æ—¶é—´èŠ±åœ¨ç­‰å¾…æ¨¡å‹å“åº”
  å·¥å…·è°ƒç”¨: 3.4% (8.45ç§’)
  å…¶ä»–å¤„ç†: 23.2% (57.00ç§’)
```

### 3ï¸âƒ£ ä½¿ç”¨åˆ†æè„šæœ¬ï¼ˆæ¨èï¼‰

è¿è¡Œåˆ†æè„šæœ¬è·å–æ›´è¯¦ç»†çš„ä¼˜åŒ–å»ºè®®ï¼š

```bash
python scripts\analyze_performance.py
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
ğŸ“Š åŠ è½½æŠ¥å‘Š: performance_report_20260206_143025.json

================================================================================
ğŸ“Š æ•´ä½“æ—¶é—´åˆ†å¸ƒåˆ†æ
================================================================================

æ€»æ‰§è¡Œæ—¶é—´: 245.67ç§’ (4.09åˆ†é’Ÿ)

æ—¶é—´åˆ†å¸ƒ:

  ğŸ¤– LLM API: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         73.4% (180.2s)
  ğŸ”§ å·¥å…·è°ƒç”¨: â–ˆâ–ˆ                                                   3.4% (8.5s)
  âš™ï¸  å…¶ä»–å¤„ç†: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                      23.2% (57.0s)

ğŸ’¡ ä¼˜åŒ–å»ºè®®:

  ä¸»è¦ç“¶é¢ˆ: LLM API è°ƒç”¨ (å  73.4%)
  â¡ï¸  ä¼˜å…ˆä¼˜åŒ– LLM è°ƒç”¨é€Ÿåº¦ï¼ˆåˆ‡æ¢æ›´å¿«çš„æ¨¡å‹ï¼‰

================================================================================
ğŸ’¡ ç»¼åˆä¼˜åŒ–å»ºè®®
================================================================================

ğŸ”´ é«˜ä¼˜å…ˆçº§ - LLM ä¼˜åŒ–
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ LLM è°ƒç”¨å  73.4%ï¼Œå»ºè®®ç«‹å³ä¼˜åŒ–
  â€¢ æ–¹æ¡ˆ 1: åˆ‡æ¢åˆ°æ›´å¿«çš„æ¨¡å‹ï¼ˆæ¨è gpt-4o-mini æˆ– gpt-3.5-turboï¼‰
  â€¢ æ–¹æ¡ˆ 2: ä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹å‡å°‘ç½‘ç»œå»¶è¿Ÿ
  â€¢ æ–¹æ¡ˆ 3: ä¼˜åŒ– Agent prompt å‡å°‘ token ä½¿ç”¨
```

## ğŸ“‹ æ ¸å¿ƒç›‘æ§æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | æ­£å¸¸èŒƒå›´ | éœ€è¦ä¼˜åŒ– |
|------|------|----------|----------|
| **LLM è°ƒç”¨å æ¯”** | LLM API æ—¶é—´ / æ€»æ—¶é—´ | 40-60% | >70% |
| **LLM å¹³å‡å“åº”** | å•æ¬¡è°ƒç”¨å¹³å‡æ—¶é—´ | 3-8ç§’ | >10ç§’ |
| **å·¥å…·è°ƒç”¨å æ¯”** | å·¥å…·æ‰§è¡Œæ—¶é—´ / æ€»æ—¶é—´ | 5-15% | >20% |
| **å…¶ä»–å¤„ç†å æ¯”** | æ¡†æ¶å’Œé€»è¾‘å¼€é”€ | 20-30% | >40% |

## ğŸ¯ å¸¸è§æ€§èƒ½é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: LLM å“åº”æ…¢ï¼ˆå æ¯” >70%ï¼Œå¹³å‡ >10ç§’ï¼‰

**åŸå› ï¼š** DeepSeek æˆ–å…¶ä»–æ¨¡å‹å“åº”é€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š**

1. **åˆ‡æ¢åˆ°æ›´å¿«çš„æ¨¡å‹** â­â­â­â­â­

```bash
# ä¿®æ”¹ .env æ–‡ä»¶
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_MODEL_NAME=gpt-4o-mini  # é€šå¸¸ 2-5 ç§’å“åº”
```

2. **ä½¿ç”¨æœ¬åœ°æ¨¡å‹** â­â­â­

```bash
# å®‰è£… Ollama
# ä¿®æ”¹ .env
OPENAI_API_BASE=http://localhost:11434/v1
OPENAI_MODEL_NAME=qwen2.5:14b
```

3. **ä¼˜åŒ– prompt å‡å°‘ tokens** â­â­

ç¼–è¾‘ `src/config/agents.yaml` ç®€åŒ– backstory å’Œ goal

### é—®é¢˜ 2: å·¥å…·è°ƒç”¨æ…¢ï¼ˆå æ¯” >20%ï¼‰

**åŸå› ï¼š** é¢‘ç¹çš„æ–‡ä»¶ I/O æˆ– RAG æ£€ç´¢æ…¢

**è§£å†³æ–¹æ¡ˆï¼š**

1. **ä¸º RAG æ·»åŠ ç¼“å­˜**

```python
# åœ¨ src/tools/rag_tools.py ä¸­
from functools import lru_cache

@lru_cache(maxsize=100)
def _run(self, query: str, top_k: int = 5):
    # æ£€ç´¢é€»è¾‘...
```

2. **æ‰¹é‡å¤„ç†æ–‡ä»¶æ“ä½œ**

å‡å°‘å•æ¬¡è¯»å†™ï¼Œæ”¹ä¸ºæ‰¹é‡æ“ä½œ

### é—®é¢˜ 3: å…¶ä»–å¤„ç†æ…¢ï¼ˆå æ¯” >40%ï¼‰

**åŸå› ï¼š** Agent æ€è€ƒæ—¶é—´é•¿æˆ–æ¡†æ¶å¼€é”€å¤§

**è§£å†³æ–¹æ¡ˆï¼š**

1. ç®€åŒ– Agent é…ç½®
2. å‡å°‘ Task çš„å¤æ‚åº¦
3. æ£€æŸ¥æ˜¯å¦æœ‰ä¸å¿…è¦çš„é‡å¤æ“ä½œ

## ğŸ“Š å¯¹æ¯”æµ‹è¯•ç¤ºä¾‹

å‡è®¾ä½ æƒ³æµ‹è¯•ä¸åŒæ¨¡å‹çš„æ€§èƒ½å·®å¼‚ï¼š

### æµ‹è¯• 1: ä½¿ç”¨ DeepSeek

```bash
# .env é…ç½®
OPENAI_MODEL_NAME=deepseek-chat

# è¿è¡Œ
python -m src.main

# æŸ¥çœ‹ç»“æœ
python scripts\analyze_performance.py
# ç»“æœ: æ€»æ—¶é—´ 10 åˆ†é’Ÿï¼ŒLLM å  75%
```

### æµ‹è¯• 2: ä½¿ç”¨ GPT-4o-mini

```bash
# .env é…ç½®
OPENAI_MODEL_NAME=gpt-4o-mini

# è¿è¡Œ
python -m src.main

# æŸ¥çœ‹ç»“æœ
python scripts\analyze_performance.py
# ç»“æœ: æ€»æ—¶é—´ 3 åˆ†é’Ÿï¼ŒLLM å  60%
# ğŸ’° æé€Ÿ 3.3 å€ï¼
```

### æµ‹è¯• 3: ä½¿ç”¨æœ¬åœ° Ollama

```bash
# .env é…ç½®
OPENAI_API_BASE=http://localhost:11434/v1
OPENAI_MODEL_NAME=qwen2.5:7b

# è¿è¡Œ
python -m src.main

# æŸ¥çœ‹ç»“æœ
python scripts\analyze_performance.py
# ç»“æœ: æ€»æ—¶é—´ 6 åˆ†é’Ÿï¼ŒLLM å  65%
# ğŸ’¡ æ¯” DeepSeek å¿«ï¼Œä¸”å®Œå…¨å…è´¹ï¼
```

## ğŸ” è¿›é˜¶ä½¿ç”¨

### æŸ¥çœ‹ JSON è¯¦ç»†æ•°æ®

```python
import json

with open('storage/performance_logs/performance_report_xxx.json') as f:
    data = json.load(f)

# æŸ¥çœ‹æ‰€æœ‰ LLM è°ƒç”¨
for call in data['llm_calls']:
    print(f"{call['duration_seconds']:.2f}s - {call['context']}")

# æŸ¥çœ‹ token ä½¿ç”¨
total_tokens = sum(c.get('total_tokens', 0) for c in data['llm_calls'])
print(f"æ€»å…±ä½¿ç”¨äº† {total_tokens:,} tokens")
```

### å¯¼å‡ºä¸º CSV åˆ†æ

```python
import pandas as pd
import json

with open('storage/performance_logs/performance_report_xxx.json') as f:
    data = json.load(f)

# LLM è°ƒç”¨è½¬ CSV
df = pd.DataFrame(data['llm_calls'])
df.to_csv('llm_analysis.csv', index=False)

# åœ¨ Excel ä¸­æ‰“å¼€ llm_analysis.csv è¿›è¡Œåˆ†æ
```

### å¯¹æ¯”å¤šæ¬¡è¿è¡Œ

```python
import json
from pathlib import Path

log_dir = Path('storage/performance_logs')
reports = sorted(log_dir.glob('performance_report_*.json'))

for report in reports[-3:]:  # æœ€è¿‘ 3 æ¬¡
    with open(report) as f:
        data = json.load(f)
        session = data['session_id']
        total = data['total_duration_seconds']
        llm_pct = data['summary']['llm_calls']['percentage_of_total']
        
        print(f"{session}: {total:.1f}s (LLM: {llm_pct:.1f}%)")

# è¾“å‡º:
# 20260206_140000: 600.5s (LLM: 75.2%)  <- ä½¿ç”¨ DeepSeek
# 20260206_143000: 180.3s (LLM: 60.1%)  <- åˆ‡æ¢åˆ° GPT-4o-mini
# 20260206_145000: 165.8s (LLM: 58.5%)  <- è¿›ä¸€æ­¥ä¼˜åŒ– prompt
```

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šæ²¡æœ‰ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š

**æ£€æŸ¥ï¼š**

1. ç¡®è®¤ `storage/performance_logs/` ç›®å½•å­˜åœ¨
2. æ£€æŸ¥æ§åˆ¶å°è¾“å‡ºæ˜¯å¦æœ‰é”™è¯¯
3. ç¡®è®¤ç³»ç»Ÿæ­£å¸¸è¿è¡Œå®Œæˆï¼ˆæ²¡æœ‰ä¸­é€”å´©æºƒï¼‰

### é—®é¢˜ï¼šLLM è°ƒç”¨æ¬¡æ•°ä¸º 0

**å¯èƒ½åŸå› ï¼š**

1. LiteLLM patch å¤±è´¥
2. CrewAI ç‰ˆæœ¬ä¸å…¼å®¹

**è§£å†³ï¼š**

æŸ¥çœ‹å¯åŠ¨æ—¶çš„ patch è¾“å‡ºï¼Œå¦‚æœçœ‹åˆ° "âš ï¸" è¯´æ˜ patch å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥ä¾èµ–ç‰ˆæœ¬

### é—®é¢˜ï¼šæŠ¥å‘Šä¸­çš„æ—¶é—´ä¸å‡†ç¡®

**å¯èƒ½åŸå› ï¼š**

1. ç³»ç»Ÿæ—¶é’Ÿé—®é¢˜
2. å¼‚æ­¥æ“ä½œæœªæ­£ç¡®è®¡æ—¶

**è§£å†³ï¼š**

å¯¹æ¯”å¤šæ¬¡è¿è¡Œçš„ç›¸å¯¹è¶‹åŠ¿ï¼Œè€Œä¸æ˜¯ç»å¯¹æ—¶é—´

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- ğŸ“– [å®Œæ•´æ€§èƒ½ç›‘æ§æ–‡æ¡£](docs/performance_monitoring.md)
- ğŸ”§ [API å‚è€ƒ](src/utils/performance_monitor.py)
- ğŸ“ [åˆ†æè„šæœ¬æºç ](scripts/analyze_performance.py)

## ğŸ’¬ å¸¸è§é—®é¢˜

**Q: æ€§èƒ½ç›‘æ§ä¼šå½±å“ç³»ç»Ÿé€Ÿåº¦å—ï¼Ÿ**

A: å‡ ä¹ä¸ä¼šã€‚ç›‘æ§ä»£ç çš„å¼€é”€é€šå¸¸ <1% æ€»æ—¶é—´ã€‚

**Q: å¯ä»¥ç¦ç”¨ç›‘æ§å—ï¼Ÿ**

A: å¯ä»¥ï¼Œåœ¨ `src/main.py` ä¸­æ³¨é‡Šæ‰ç›‘æ§åˆå§‹åŒ–ä»£ç å³å¯ã€‚

**Q: æ”¯æŒå“ªäº› LLM æ¨¡å‹ï¼Ÿ**

A: æ”¯æŒæ‰€æœ‰å…¼å®¹ OpenAI API çš„æ¨¡å‹ï¼ˆOpenAIã€DeepSeekã€Ollama ç­‰ï¼‰ã€‚

**Q: å¦‚ä½•æ¸…ç†æ—§æŠ¥å‘Šï¼Ÿ**

A: æ‰‹åŠ¨åˆ é™¤ `storage/performance_logs/` ä¸­çš„æ—§æ–‡ä»¶å³å¯ã€‚

## ğŸ‰ æ€»ç»“

1. âœ… **é›¶é…ç½®å¯ç”¨** - è¿è¡Œç³»ç»Ÿå³è‡ªåŠ¨ç›‘æ§
2. âœ… **å®æ—¶åé¦ˆ** - æ§åˆ¶å°å®æ—¶æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
3. âœ… **è¯¦ç»†æŠ¥å‘Š** - è‡ªåŠ¨ç”Ÿæˆ JSON + æ–‡æœ¬æŠ¥å‘Š
4. âœ… **æ™ºèƒ½åˆ†æ** - è‡ªåŠ¨è¯†åˆ«ç“¶é¢ˆå¹¶ç»™å‡ºå»ºè®®
5. âœ… **æ˜“äºå¯¹æ¯”** - æ”¯æŒå¤šæ¬¡è¿è¡Œå¯¹æ¯”ä¼˜åŒ–æ•ˆæœ

**å»ºè®®å·¥ä½œæµç¨‹ï¼š**

```
1. è¿è¡Œç³»ç»Ÿ â†’ 2. æŸ¥çœ‹æŠ¥å‘Š â†’ 3. è¯†åˆ«ç“¶é¢ˆ â†’ 4. åº”ç”¨ä¼˜åŒ– â†’ 5. é‡æ–°æµ‹è¯•
```

æŒç»­è¿­ä»£ï¼Œç›´åˆ°è¾¾åˆ°æ»¡æ„çš„æ€§èƒ½æ°´å¹³ï¼ ğŸš€
