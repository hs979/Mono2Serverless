"""
æ€§èƒ½ç›‘æ§æ¨¡å—
ç”¨äºè®°å½• LLM API è°ƒç”¨æ—¶é—´ã€Agent å¤„ç†æ—¶é—´ç­‰æ€§èƒ½æŒ‡æ ‡
"""
import time
import json
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, List
from functools import wraps
import threading


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨ï¼Œè®°å½•å„ç§æ—¶é—´æŒ‡æ ‡"""
    
    def __init__(self, log_dir: Path):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # è®°å½•æ•°æ®
        self.llm_calls: List[Dict[str, Any]] = []
        self.task_times: List[Dict[str, Any]] = []
        self.agent_times: List[Dict[str, Any]] = []
        self.tool_calls: List[Dict[str, Any]] = []
        
        # ä¼šè¯ä¿¡æ¯
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_start = time.time()
        
        # çº¿ç¨‹é”
        self._lock = threading.Lock()
        
        print(f"ğŸ“Š æ€§èƒ½ç›‘æ§å·²å¯åŠ¨ - Session ID: {self.session_id}")
    
    def record_llm_call(
        self,
        model: str,
        prompt_tokens: Optional[int] = None,
        completion_tokens: Optional[int] = None,
        total_tokens: Optional[int] = None,
        start_time: Optional[float] = None,
        end_time: Optional[float] = None,
        duration: Optional[float] = None,
        success: bool = True,
        error: Optional[str] = None,
        context: Optional[str] = None
    ):
        """è®°å½•ä¸€æ¬¡ LLM API è°ƒç”¨"""
        with self._lock:
            if duration is None and start_time and end_time:
                duration = end_time - start_time
            
            record = {
                "timestamp": datetime.now().isoformat(),
                "model": model,
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens,
                "duration_seconds": duration,
                "success": success,
                "error": error,
                "context": context  # ä¾‹å¦‚: "agent: architect, task: blueprint"
            }
            self.llm_calls.append(record)
            
            # å®æ—¶æ‰“å°
            print(f"ğŸ¤– LLM è°ƒç”¨ [{model}]: {duration:.2f}s | "
                  f"Tokens: {total_tokens or 'N/A'} | "
                  f"Context: {context or 'N/A'}")
    
    def record_task(
        self,
        task_name: str,
        agent_name: str,
        start_time: float,
        end_time: float,
        success: bool = True,
        output_size: Optional[int] = None
    ):
        """è®°å½•ä¸€ä¸ª Task çš„æ‰§è¡Œ"""
        with self._lock:
            duration = end_time - start_time
            record = {
                "timestamp": datetime.now().isoformat(),
                "task_name": task_name,
                "agent_name": agent_name,
                "duration_seconds": duration,
                "success": success,
                "output_size": output_size
            }
            self.task_times.append(record)
            
            print(f"ğŸ“‹ Task å®Œæˆ [{task_name}]: {duration:.2f}s | Agent: {agent_name}")
    
    def record_agent_action(
        self,
        agent_name: str,
        action_type: str,
        start_time: float,
        end_time: float,
        details: Optional[str] = None
    ):
        """è®°å½• Agent çš„å•æ¬¡æ“ä½œ"""
        with self._lock:
            duration = end_time - start_time
            record = {
                "timestamp": datetime.now().isoformat(),
                "agent_name": agent_name,
                "action_type": action_type,
                "duration_seconds": duration,
                "details": details
            }
            self.agent_times.append(record)
    
    def record_tool_call(
        self,
        tool_name: str,
        agent_name: str,
        start_time: float,
        end_time: float,
        success: bool = True
    ):
        """è®°å½•å·¥å…·è°ƒç”¨"""
        with self._lock:
            duration = end_time - start_time
            record = {
                "timestamp": datetime.now().isoformat(),
                "tool_name": tool_name,
                "agent_name": agent_name,
                "duration_seconds": duration,
                "success": success
            }
            self.tool_calls.append(record)
            
            print(f"ğŸ”§ Tool è°ƒç”¨ [{tool_name}]: {duration:.3f}s | Agent: {agent_name}")
    
    def start_timer(self) -> float:
        """å¼€å§‹è®¡æ—¶"""
        return time.time()
    
    def save_report(self):
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        total_duration = time.time() - self.session_start
        
        report = {
            "session_id": self.session_id,
            "total_duration_seconds": total_duration,
            "summary": self._generate_summary(),
            "llm_calls": self.llm_calls,
            "task_times": self.task_times,
            "agent_times": self.agent_times,
            "tool_calls": self.tool_calls
        }
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = self.log_dir / f"performance_report_{self.session_id}.json"
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, indent=2, ensure_ascii=False, fp=f)
        
        # ä¿å­˜ç®€åŒ–çš„ç»Ÿè®¡æŠ¥å‘Š
        summary_file = self.log_dir / f"performance_summary_{self.session_id}.txt"
        with open(summary_file, "w", encoding="utf-8") as f:
            f.write(self._format_summary())
        
        print(f"\nğŸ“Š æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"  - è¯¦ç»†æŠ¥å‘Š: {report_file}")
        print(f"  - ç»Ÿè®¡æ‘˜è¦: {summary_file}")
        
        return report
    
    def _generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆç»Ÿè®¡æ‘˜è¦"""
        total_duration = time.time() - self.session_start
        
        # LLM è°ƒç”¨ç»Ÿè®¡
        llm_total_time = sum(call.get("duration_seconds", 0) for call in self.llm_calls if call.get("duration_seconds"))
        llm_count = len(self.llm_calls)
        llm_avg_time = llm_total_time / llm_count if llm_count > 0 else 0
        
        # Task ç»Ÿè®¡
        task_total_time = sum(task.get("duration_seconds", 0) for task in self.task_times)
        task_count = len(self.task_times)
        
        # Tool è°ƒç”¨ç»Ÿè®¡
        tool_total_time = sum(tool.get("duration_seconds", 0) for tool in self.tool_calls)
        tool_count = len(self.tool_calls)
        
        # è®¡ç®—æ¯”ä¾‹
        llm_percentage = (llm_total_time / total_duration * 100) if total_duration > 0 else 0
        tool_percentage = (tool_total_time / total_duration * 100) if total_duration > 0 else 0
        
        return {
            "total_duration_seconds": total_duration,
            "llm_calls": {
                "count": llm_count,
                "total_time_seconds": llm_total_time,
                "average_time_seconds": llm_avg_time,
                "percentage_of_total": llm_percentage
            },
            "tasks": {
                "count": task_count,
                "total_time_seconds": task_total_time
            },
            "tool_calls": {
                "count": tool_count,
                "total_time_seconds": tool_total_time,
                "percentage_of_total": tool_percentage
            },
            "other_time_seconds": total_duration - llm_total_time - tool_total_time,
            "other_percentage": 100 - llm_percentage - tool_percentage
        }
    
    def _format_summary(self) -> str:
        """æ ¼å¼åŒ–ç»Ÿè®¡æ‘˜è¦ä¸ºæ–‡æœ¬"""
        summary = self._generate_summary()
        total = summary["total_duration_seconds"]
        
        lines = [
            "=" * 80,
            f"æ€§èƒ½åˆ†ææŠ¥å‘Š - Session: {self.session_id}",
            "=" * 80,
            "",
            f"ğŸ“Š æ€»æ‰§è¡Œæ—¶é—´: {total:.2f}ç§’ ({total/60:.2f}åˆ†é’Ÿ)",
            "",
            "=" * 80,
            "ğŸ¤– LLM API è°ƒç”¨ç»Ÿè®¡",
            "=" * 80,
            f"  è°ƒç”¨æ¬¡æ•°: {summary['llm_calls']['count']}",
            f"  æ€»è€—æ—¶: {summary['llm_calls']['total_time_seconds']:.2f}ç§’",
            f"  å¹³å‡è€—æ—¶: {summary['llm_calls']['average_time_seconds']:.2f}ç§’/æ¬¡",
            f"  å æ€»æ—¶é—´æ¯”ä¾‹: {summary['llm_calls']['percentage_of_total']:.1f}%",
            "",
            "=" * 80,
            "ğŸ“‹ Task æ‰§è¡Œç»Ÿè®¡",
            "=" * 80,
            f"  ä»»åŠ¡æ•°é‡: {summary['tasks']['count']}",
            f"  æ€»è€—æ—¶: {summary['tasks']['total_time_seconds']:.2f}ç§’",
            ""
        ]
        
        # æ¯ä¸ª Task çš„è¯¦ç»†æ—¶é—´
        if self.task_times:
            lines.append("  å„ä»»åŠ¡è€—æ—¶:")
            for task in self.task_times:
                lines.append(f"    - {task['task_name']}: {task['duration_seconds']:.2f}ç§’ (Agent: {task['agent_name']})")
            lines.append("")
        
        lines.extend([
            "=" * 80,
            "ğŸ”§ å·¥å…·è°ƒç”¨ç»Ÿè®¡",
            "=" * 80,
            f"  è°ƒç”¨æ¬¡æ•°: {summary['tool_calls']['count']}",
            f"  æ€»è€—æ—¶: {summary['tool_calls']['total_time_seconds']:.2f}ç§’",
            f"  å æ€»æ—¶é—´æ¯”ä¾‹: {summary['tool_calls']['percentage_of_total']:.1f}%",
            "",
            "=" * 80,
            "ğŸ“ˆ æ—¶é—´åˆ†å¸ƒ",
            "=" * 80,
            f"  LLM API è°ƒç”¨: {summary['llm_calls']['percentage_of_total']:.1f}% ({summary['llm_calls']['total_time_seconds']:.2f}ç§’)",
            f"  å·¥å…·è°ƒç”¨: {summary['tool_calls']['percentage_of_total']:.1f}% ({summary['tool_calls']['total_time_seconds']:.2f}ç§’)",
            f"  å…¶ä»–å¤„ç†: {summary['other_percentage']:.1f}% ({summary['other_time_seconds']:.2f}ç§’)",
            "",
        ])
        
        # LLM è°ƒç”¨è¯¦ç»†åˆ—è¡¨
        if self.llm_calls:
            lines.extend([
                "=" * 80,
                "ğŸ¤– LLM è°ƒç”¨è¯¦ç»†è®°å½•",
                "=" * 80,
            ])
            for i, call in enumerate(self.llm_calls, 1):
                duration = call.get("duration_seconds", 0)
                tokens = call.get("total_tokens", "N/A")
                context = call.get("context", "N/A")
                lines.append(f"  #{i}: {duration:.2f}s | Tokens: {tokens} | {context}")
            lines.append("")
        
        return "\n".join(lines)
    
    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        print("\n" + self._format_summary())


# å…¨å±€ç›‘æ§å®ä¾‹
_monitor: Optional[PerformanceMonitor] = None


def get_monitor() -> Optional[PerformanceMonitor]:
    """è·å–å…¨å±€ç›‘æ§å®ä¾‹"""
    return _monitor


def init_monitor(log_dir: Path) -> PerformanceMonitor:
    """åˆå§‹åŒ–å…¨å±€ç›‘æ§å®ä¾‹"""
    global _monitor
    _monitor = PerformanceMonitor(log_dir)
    return _monitor


def time_it(name: str, context: Optional[str] = None):
    """è£…é¥°å™¨ï¼šè‡ªåŠ¨è®°å½•å‡½æ•°æ‰§è¡Œæ—¶é—´"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            monitor = get_monitor()
            start = time.time()
            try:
                result = func(*args, **kwargs)
                if monitor:
                    end = time.time()
                    monitor.record_agent_action(
                        agent_name=context or "unknown",
                        action_type=name,
                        start_time=start,
                        end_time=end
                    )
                return result
            except Exception as e:
                if monitor:
                    end = time.time()
                    monitor.record_agent_action(
                        agent_name=context or "unknown",
                        action_type=name,
                        start_time=start,
                        end_time=end,
                        details=f"Error: {str(e)}"
                    )
                raise
        return wrapper
    return decorator
