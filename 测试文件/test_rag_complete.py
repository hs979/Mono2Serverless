"""
å®Œæ•´æµ‹è¯• RAG ç´¢å¼•æ„å»ºå’Œè¯­ä¹‰æœç´¢åŠŸèƒ½

æµ‹è¯•æµç¨‹ï¼š
1. æ„å»ºç´¢å¼•ï¼ˆåŸºäº static_analyzer çš„ç»“æœï¼‰
2. åŠ è½½ç´¢å¼•å¹¶æµ‹è¯•è¯­ä¹‰æœç´¢
3. éªŒè¯å‰ç«¯å’Œåç«¯æ–‡ä»¶çš„ç´¢å¼•ç­–ç•¥
4. æ¨¡æ‹Ÿ Agent ä½¿ç”¨åœºæ™¯
"""
import json
import tempfile
import shutil
from pathlib import Path

from llama_index.core import StorageContext, load_index_from_storage
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

from src.preprocessor.build_rag import (
    load_analysis_report,
    build_documents,
    build_and_persist_index
)


def test_build_index():
    """æµ‹è¯•1ï¼šæ„å»ºç´¢å¼•"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•1ï¼šæ„å»º RAG ç´¢å¼•")
    print("=" * 70)
    
    # ä½¿ç”¨ coffee_test.jsonï¼ˆNode.js é¡¹ç›®ï¼‰
    test_file = Path("static_result/coffee_test.json")
    
    if not test_file.exists():
        print(f"[WARN] æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        print("è¯·å…ˆè¿è¡Œ static_analyzer.py ç”Ÿæˆæµ‹è¯•æ•°æ®")
        return None
    
    # åŠ è½½åˆ†ææŠ¥å‘Š
    analysis_report = load_analysis_report(test_file)
    
    # æ¨¡æ‹Ÿé¡¹ç›®æ ¹ç›®å½•ï¼ˆè¿™é‡Œæˆ‘ä»¬åªæµ‹è¯• document æ„å»ºï¼Œä¸éœ€è¦å®é™…æ–‡ä»¶ï¼‰
    print(f"\nåˆ†ææŠ¥å‘Šç»Ÿè®¡:")
    print(f"  - æ–‡ä»¶æ ‡ç­¾: {len(analysis_report.get('file_tags', {}))} ä¸ª")
    print(f"  - ç¬¦å·è¡¨: {len(analysis_report.get('symbol_table', []))} ä¸ª")
    print(f"  - å…¥å£ç‚¹: {len(analysis_report.get('entry_points', []))} ä¸ª")
    
    # æ£€æŸ¥ç¬¦å·ç±»å‹åˆ†å¸ƒ
    symbol_table = analysis_report.get("symbol_table", [])
    kind_counts = {}
    for symbol in symbol_table:
        kind = symbol.get("kind", "unknown")
        kind_counts[kind] = kind_counts.get(kind, 0) + 1
    
    print(f"\nç¬¦å·ç±»å‹åˆ†å¸ƒ:")
    for kind, count in sorted(kind_counts.items()):
        print(f"  - {kind}: {count}")
    
    print("\n[PASS] ç´¢å¼•æ„å»ºæµ‹è¯•å‡†å¤‡å®Œæˆ")
    return analysis_report


def test_semantic_search():
    """æµ‹è¯•2ï¼šè¯­ä¹‰æœç´¢åŠŸèƒ½"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•2ï¼šè¯­ä¹‰æœç´¢åŠŸèƒ½")
    print("=" * 70)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²æ„å»ºçš„ç´¢å¼•
    index_dir = Path("storage/code_index")
    
    if not index_dir.exists() or not (index_dir / "docstore.json").exists():
        print(f"[WARN] ç´¢å¼•ç›®å½•ä¸å­˜åœ¨: {index_dir}")
        print("è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤æ„å»ºç´¢å¼•:")
        print("  python src/preprocessor/static_analyzer.py --monolith-root <your_project>")
        print("  python src/preprocessor/build_rag.py --monolith-root <your_project>")
        return False
    
    print(f"åŠ è½½ç´¢å¼•: {index_dir}")
    
    try:
        # åŠ è½½ embedding æ¨¡å‹
        embed_model = HuggingFaceEmbedding(model_name="microsoft/codebert-base")
        
        # åŠ è½½ç´¢å¼•
        storage_context = StorageContext.from_defaults(persist_dir=str(index_dir))
        index = load_index_from_storage(storage_context, embed_model=embed_model)
        
        # åˆ›å»ºæŸ¥è¯¢å¼•æ“
        query_engine = index.as_query_engine(similarity_top_k=5)
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            {
                "query": "How to connect to DynamoDB database?",
                "expected_keywords": ["dynamodb", "database", "table"],
                "description": "åç«¯æ•°æ®åº“æŸ¥è¯¢"
            },
            {
                "query": "Where is user authentication handled?",
                "expected_keywords": ["auth", "login", "user"],
                "description": "åç«¯è®¤è¯æŸ¥è¯¢"
            },
            {
                "query": "Which functions handle API routes?",
                "expected_keywords": ["route", "get", "post", "api"],
                "description": "åç«¯è·¯ç”±æŸ¥è¯¢"
            },
        ]
        
        print(f"\næ‰§è¡Œ {len(test_queries)} ä¸ªè¯­ä¹‰æœç´¢æµ‹è¯•...\n")
        
        for i, test in enumerate(test_queries, 1):
            print(f"æŸ¥è¯¢ {i}: {test['description']}")
            print(f"  é—®é¢˜: {test['query']}")
            
            # æ‰§è¡ŒæŸ¥è¯¢
            response = query_engine.query(test['query'])
            
            print(f"  ç»“æœ: {str(response)[:200]}...")
            
            # æ£€æŸ¥æºèŠ‚ç‚¹
            if hasattr(response, 'source_nodes') and response.source_nodes:
                print(f"  æ‰¾åˆ° {len(response.source_nodes)} ä¸ªç›¸å…³ä»£ç ç‰‡æ®µ:")
                
                for j, node in enumerate(response.source_nodes[:3], 1):
                    metadata = node.metadata
                    score = node.score if hasattr(node, 'score') else 0.0
                    
                    print(f"    [{j}] ç›¸ä¼¼åº¦: {score:.4f}")
                    
                    # æ˜¾ç¤º metadataï¼ˆåç«¯æ–‡ä»¶åº”è¯¥æœ‰ï¼Œå‰ç«¯æ–‡ä»¶ä¸ºç©ºï¼‰
                    if metadata:
                        print(f"        æ–‡ä»¶: {metadata.get('file_path', 'N/A')}")
                        print(f"        å‡½æ•°: {metadata.get('function_name', 'N/A')}")
                        print(f"        ç±»å‹: {metadata.get('type', 'N/A')}")
                        print(f"        è¡Œå·: {metadata.get('start_line', 'N/A')}-{metadata.get('end_line', 'N/A')}")
                    else:
                        print(f"        (å‰ç«¯æ–‡ä»¶ï¼Œæ—  metadata)")
                    
                    # æ˜¾ç¤ºä»£ç ç‰‡æ®µé¢„è§ˆ
                    text_preview = node.text[:100].replace('\n', ' ')
                    print(f"        ä»£ç : {text_preview}...")
            else:
                print(f"  [WARN] æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
            
            print()
        
        print("[PASS] è¯­ä¹‰æœç´¢æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"[FAIL] è¯­ä¹‰æœç´¢æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_frontend_backend_separation():
    """æµ‹è¯•3ï¼šéªŒè¯å‰ç«¯å’Œåç«¯åˆ†ç¦»ç­–ç•¥"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•3ï¼šéªŒè¯å‰ç«¯/åç«¯åˆ†ç¦»ç­–ç•¥")
    print("=" * 70)
    
    index_dir = Path("storage/code_index")
    
    if not index_dir.exists():
        print(f"[WARN] ç´¢å¼•ç›®å½•ä¸å­˜åœ¨: {index_dir}")
        return False
    
    try:
        # åŠ è½½ docstore æ£€æŸ¥ metadata
        docstore_path = index_dir / "docstore.json"
        with open(docstore_path, 'r', encoding='utf-8') as f:
            docstore = json.load(f)
        
        # ç»Ÿè®¡
        total_docs = len(docstore.get('docstore/data', {}))
        backend_with_metadata = 0
        frontend_no_metadata = 0
        
        print(f"\næ–‡æ¡£æ€»æ•°: {total_docs}")
        print(f"\næ£€æŸ¥ metadata ç­–ç•¥...")
        
        for doc_id, doc_data in docstore.get('docstore/data', {}).items():
            metadata = doc_data.get('metadata', {})
            
            # åç«¯æ–‡ä»¶åº”è¯¥æœ‰ metadata
            if metadata and 'file_path' in metadata:
                file_path = metadata.get('file_path', '')
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºå‰ç«¯æ–‡ä»¶
                is_frontend = any(part in file_path for part in ['frontend', 'client', 'ui', 'web', 'public'])
                
                if not is_frontend:
                    backend_with_metadata += 1
            
            # å‰ç«¯æ–‡ä»¶åº”è¯¥æ²¡æœ‰ metadataï¼ˆç©ºå¯¹è±¡ï¼‰
            if not metadata or len(metadata) == 0:
                frontend_no_metadata += 1
        
        print(f"  - åç«¯æ–‡æ¡£ï¼ˆæœ‰ metadataï¼‰: {backend_with_metadata}")
        print(f"  - å‰ç«¯æ–‡æ¡£ï¼ˆæ—  metadataï¼‰: {frontend_no_metadata}")
        
        if backend_with_metadata > 0:
            print(f"\n[PASS] æ£€æµ‹åˆ°åç«¯æ–‡æ¡£å¸¦æœ‰ metadata")
        
        if frontend_no_metadata > 0:
            print(f"[PASS] æ£€æµ‹åˆ°å‰ç«¯æ–‡æ¡£æ²¡æœ‰ metadata")
        
        if backend_with_metadata == 0 and frontend_no_metadata == 0:
            print(f"[WARN] æœªæ£€æµ‹åˆ°æ˜ç¡®çš„å‰ç«¯/åç«¯åˆ†ç¦»")
        
        return True
        
    except Exception as e:
        print(f"[FAIL] éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_agent_use_case():
    """æµ‹è¯•4ï¼šæ¨¡æ‹Ÿ Agent ä½¿ç”¨åœºæ™¯"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•4ï¼šæ¨¡æ‹Ÿ Agent ä½¿ç”¨åœºæ™¯")
    print("=" * 70)
    
    index_dir = Path("storage/code_index")
    
    if not index_dir.exists():
        print(f"[WARN] ç´¢å¼•ç›®å½•ä¸å­˜åœ¨: {index_dir}")
        return False
    
    try:
        # åŠ è½½ç´¢å¼•
        embed_model = HuggingFaceEmbedding(model_name="microsoft/codebert-base")
        storage_context = StorageContext.from_defaults(persist_dir=str(index_dir))
        index = load_index_from_storage(storage_context, embed_model=embed_model)
        query_engine = index.as_query_engine(similarity_top_k=3)
        
        # æ¨¡æ‹Ÿ Agent åœºæ™¯
        scenarios = [
            {
                "scenario": "Agent éœ€è¦æ‰¾åˆ°å¤„ç†è®¢å•çš„å‡½æ•°",
                "query": "Find functions that process orders and handle order creation",
                "expectation": "åº”è¯¥è¿”å›å¸¦æœ‰ metadata çš„åç«¯å‡½æ•°ï¼ˆå‡½æ•°åã€æ–‡ä»¶è·¯å¾„ã€è¡Œå·ï¼‰"
            },
            {
                "scenario": "Agent éœ€è¦æ‰¾åˆ° API é…ç½®æ–‡ä»¶",
                "query": "Where is the API configuration defined?",
                "expectation": "å¯èƒ½è¿”å›å‰ç«¯é…ç½®æ–‡ä»¶ï¼ˆæ•´æ–‡ä»¶å†…å®¹ï¼‰æˆ–åç«¯é…ç½®"
            },
            {
                "scenario": "Agent éœ€è¦æ‰¾åˆ°æ•°æ®åº“ç›¸å…³çš„ä»£ç ",
                "query": "Show me database connection and query functions",
                "expectation": "åº”è¯¥è¿”å›åç«¯æ•°æ®åº“å‡½æ•°ï¼ˆå¸¦ metadataï¼‰"
            }
        ]
        
        print(f"\næ¨¡æ‹Ÿ {len(scenarios)} ä¸ª Agent ä½¿ç”¨åœºæ™¯...\n")
        
        for i, scenario in enumerate(scenarios, 1):
            print(f"åœºæ™¯ {i}: {scenario['scenario']}")
            print(f"  æŸ¥è¯¢: {scenario['query']}")
            print(f"  æœŸæœ›: {scenario['expectation']}")
            
            response = query_engine.query(scenario['query'])
            
            if hasattr(response, 'source_nodes') and response.source_nodes:
                print(f"  âœ“ æ‰¾åˆ° {len(response.source_nodes)} ä¸ªç›¸å…³ç»“æœ")
                
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªç»“æœ
                first_node = response.source_nodes[0]
                metadata = first_node.metadata
                
                if metadata:
                    print(f"    ç±»å‹: åç«¯ä»£ç ç‰‡æ®µ")
                    print(f"    æ–‡ä»¶: {metadata.get('file_path', 'N/A')}")
                    print(f"    å‡½æ•°: {metadata.get('function_name', 'N/A')}")
                    print(f"    è¡Œå·: {metadata.get('start_line', 'N/A')}-{metadata.get('end_line', 'N/A')}")
                    print(f"    [PASS] Agent å¯ä»¥ç²¾ç¡®å®šä½åˆ°ä»£ç ä½ç½®")
                else:
                    print(f"    ç±»å‹: å‰ç«¯æ•´æ–‡ä»¶")
                    print(f"    [PASS] Agent è·å–åˆ°å®Œæ•´æ–‡ä»¶å†…å®¹")
            else:
                print(f"  âœ— æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
            
            print()
        
        print("[PASS] Agent ä½¿ç”¨åœºæ™¯æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"[FAIL] Agent æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 70)
    print("RAG å®Œæ•´åŠŸèƒ½æµ‹è¯•")
    print("=" * 70)
    
    results = {
        "build_index": False,
        "semantic_search": False,
        "frontend_backend": False,
        "agent_use_case": False
    }
    
    # æµ‹è¯•1ï¼šæ„å»ºç´¢å¼•ï¼ˆåŸºäºç°æœ‰åˆ†ææŠ¥å‘Šï¼‰
    analysis_report = test_build_index()
    if analysis_report:
        results["build_index"] = True
    
    # æµ‹è¯•2ï¼šè¯­ä¹‰æœç´¢
    if test_semantic_search():
        results["semantic_search"] = True
    
    # æµ‹è¯•3ï¼šéªŒè¯å‰ç«¯/åç«¯åˆ†ç¦»
    if test_frontend_backend_separation():
        results["frontend_backend"] = True
    
    # æµ‹è¯•4ï¼šAgent ä½¿ç”¨åœºæ™¯
    if test_agent_use_case():
        results["agent_use_case"] = True
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    
    passed = sum(results.values())
    total = len(results)
    
    for test_name, result in results.items():
        status = "[PASS]" if result else "[SKIP]"
        print(f"{status} {test_name}")
    
    print(f"\né€šè¿‡: {passed}/{total}")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼RAG ç´¢å¼•å’Œè¯­ä¹‰æœç´¢åŠŸèƒ½æ­£å¸¸")
        print("\nAgent å¯ä»¥:")
        print("  âœ“ é€šè¿‡è¯­ä¹‰æœç´¢æ‰¾åˆ°ç›¸å…³ä»£ç ")
        print("  âœ“ è·å–åç«¯å‡½æ•°çš„ç²¾ç¡®ä½ç½®ï¼ˆæ–‡ä»¶ã€å‡½æ•°åã€è¡Œå·ï¼‰")
        print("  âœ“ è·å–å‰ç«¯æ–‡ä»¶çš„å®Œæ•´å†…å®¹")
        return 0
    elif results["semantic_search"]:
        print("\nâœ“ æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸ï¼šè¯­ä¹‰æœç´¢å¯ç”¨")
        return 0
    else:
        print("\nâš  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡æˆ–è·³è¿‡")
        return 1


if __name__ == "__main__":
    exit(main())
